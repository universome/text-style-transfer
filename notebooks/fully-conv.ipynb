{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "% env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path += ['..', '../src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.vocab import Vocab\n",
    "\n",
    "DATA_PATH = '../data/generated'\n",
    "max_len = 100\n",
    "\n",
    "get_path = lambda d: os.path.join(DATA_PATH, d)\n",
    "read_data = lambda d: open(get_path(d)).read().splitlines()\n",
    "tokenize = lambda c,v: [[v.token2id.get(t, v.unk) for t in s.split()] for s in c]\n",
    "cut_len = lambda c: [s[:max_len-2] for s in c]\n",
    "\n",
    "train_src = read_data('europarl.en.tok.bpe')\n",
    "train_trg = read_data('europarl.fr.tok.bpe')\n",
    "\n",
    "# Let's remove empty sentences\n",
    "filter_empty = lambda c,empty_idx: [s for i,s in enumerate(c) if not i in empty_idx]\n",
    "get_empty_idx = lambda src,trg: set(i for i,(s,t) in enumerate(zip(src, trg)) if len(s) == 0 or len(t) == 0)\n",
    "empty_idx = get_empty_idx(train_src, train_trg)\n",
    "train_src = filter_empty(train_src, empty_idx)\n",
    "train_trg = filter_empty(train_trg, empty_idx)\n",
    "\n",
    "vocab_src = Vocab.from_sequences(train_src)\n",
    "vocab_trg = Vocab.from_sequences(train_trg)\n",
    "\n",
    "train_src_idx = cut_len(tokenize(train_src, vocab_src))\n",
    "train_trg_idx = cut_len(tokenize(train_trg, vocab_trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_src_idx, val_src_idx = train_test_split(train_src_idx, test_size=1000, random_state=42)\n",
    "train_trg_idx, val_trg_idx = train_test_split(train_trg_idx, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from src.vocab import constants\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, dim_size, vocab_src_len, vocab_trg_len, n_convs=50, kernel_size=5, dropout_p=0.2):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        conv = lambda: nn.Conv1d(dim_size, dim_size, kernel_size, padding=kernel_size//2)\n",
    "        expanding_conv = lambda: nn.Conv1d(dim_size, dim_size, kernel_size, padding=kernel_size-1)\n",
    "        selu = lambda: nn.SELU()\n",
    "        \n",
    "        convs = lambda n: [(conv(), selu()) for _ in range(n)]\n",
    "        expanding_convs = lambda n: [(expanding_conv(), selu()) for _ in range(n)]\n",
    "        \n",
    "        convs_1 = convs(n_convs // 2)\n",
    "        expandings = expanding_convs(10)\n",
    "        convs_2 = convs(n_convs // 2)\n",
    "        layers = convs_1 + expandings + convs_2\n",
    "        layers = np.array(layers).flatten()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_src_len, dim_size, padding_idx=constants.PAD)\n",
    "        self.convs = nn.Sequential(*layers)\n",
    "        self.vec_to_logits = nn.Linear(dim_size, vocab_trg_len, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x).transpose(1,2)\n",
    "        x = self.convs(x)\n",
    "        x = self.vec_to_logits(x.transpose(1,2))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "from src.vocab import constants\n",
    "from src.utils.common import variable\n",
    "\n",
    "def pull_to_len(var:Variable, length:int):\n",
    "    \"\"\"\n",
    "    Contracts or expands 2D-tensor to a desired length\n",
    "    filling with PADs\n",
    "    \"\"\"\n",
    "    if var.size(1) == length:\n",
    "        return var\n",
    "    elif var.size(1) > length:\n",
    "        return var[:,:length]\n",
    "    else:\n",
    "        num_pads_to_add = length - var.size(1)\n",
    "        to_add = variable(torch.LongTensor(var.size(0), num_pads_to_add))\n",
    "        to_add.fill_(constants.PAD)\n",
    "        to_add.cuda()\n",
    "        var = torch.cat((var, to_add), 1)\n",
    "        \n",
    "        return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.bleu import compute_bleu_for_sents\n",
    "from src.utils.data_utils import remove_spec_symbols\n",
    "\n",
    "def compute_bleu(logits, trg):\n",
    "    logits = logits.view(*trg.size(), logits.size(1))\n",
    "    tokens = logits.max(dim=2)[1]\n",
    "    \n",
    "    tokens = remove_spec_symbols(tokens.data.cpu().numpy().tolist())\n",
    "    trg = remove_spec_symbols(trg.data.cpu().numpy().tolist())\n",
    "    \n",
    "    translations = vocab_trg.remove_bpe_many(vocab_trg.detokenize_many(tokens))\n",
    "    targets = vocab_trg.remove_bpe_many(vocab_trg.detokenize_many(trg))\n",
    "    \n",
    "    bleu = compute_bleu_for_sents(translations, targets)\n",
    "    \n",
    "    return bleu, translations, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm; tqdm.monitor_interval = 0\n",
    "\n",
    "from src.dataloaders import Batcher\n",
    "from src.vocab import constants\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "model = CNN(256, len(vocab_src), len(vocab_trg))\n",
    "optimizer = Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "training_data = Batcher(train_src_idx, train_trg_idx, vocab_src.token2id,\n",
    "                        vocab_trg.token2id, batch_size=32, shuffle=True)\n",
    "val_data = Batcher(val_src_idx[:256], val_trg_idx[:256], vocab_src.token2id,\n",
    "                   vocab_trg.token2id, batch_size=32, shuffle=False)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "model.train()\n",
    "loss_history = []\n",
    "bleu_history = []\n",
    "val_loss_history = []\n",
    "val_iters = []\n",
    "val_bleu_history = []\n",
    "num_iters_done = 0\n",
    "max_num_epochs = 50\n",
    "\n",
    "try:\n",
    "    for i in range(max_num_epochs):\n",
    "        for batch in tqdm(training_data, leave=False):\n",
    "            src, trg = batch\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(src)\n",
    "            trg = pull_to_len(trg, pred.size(1))\n",
    "            pred = pred.view(-1, len(vocab_trg))\n",
    "            \n",
    "            loss = criterion(pred, trg.contiguous().view(-1))\n",
    "            bleu = compute_bleu(pred, trg)[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_history.append(loss.data[0])\n",
    "            bleu_history.append(bleu)\n",
    "\n",
    "            if num_iters_done % 50 == 0:\n",
    "                clear_output(True)\n",
    "                plt.figure(figsize=[16,6])\n",
    "                plt.subplot(121)\n",
    "                plt.title(\"Loss history\")\n",
    "                plt.plot(loss_history, color='#33ACFF')\n",
    "                plt.plot(pd.DataFrame(np.array(loss_history)).ewm(span=100).mean(), label='Training loss')\n",
    "                plt.plot(val_iters, val_loss_history, label='Validation loss', c='red')\n",
    "                \n",
    "                plt.subplot(122)\n",
    "                plt.title('BLEU history')\n",
    "                plt.plot(bleu_history, color='#33ACFF')\n",
    "                plt.plot(pd.DataFrame(np.array(bleu_history)).ewm(span=100).mean(), label='Training BLEU')\n",
    "                plt.plot(val_iters, val_bleu_history, label='Validation BLEU', c='red')\n",
    "                \n",
    "                plt.grid()\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "            if num_iters_done % 100 == 0:\n",
    "                val_losses = []\n",
    "                val_bleus = []\n",
    "\n",
    "                for val_batch in val_data:\n",
    "                    val_src, val_trg = val_batch\n",
    "                    val_pred = model(val_src)\n",
    "                    val_trg = pull_to_len(val_trg, val_pred.size(1))\n",
    "                    val_pred = val_pred.view(-1, len(vocab_trg))\n",
    "                    val_loss = criterion(val_pred, val_trg.contiguous().view(-1))\n",
    "                    val_losses.append(val_loss.data[0])\n",
    "                    val_bleu = compute_bleu(val_pred, val_trg)[0]\n",
    "                    val_bleus.append(val_bleu)\n",
    "\n",
    "                val_loss_history.append(np.mean(val_losses))\n",
    "                val_bleu_history.append(np.mean(val_bleus))\n",
    "                val_iters.append(num_iters_done)\n",
    "\n",
    "            num_iters_done += 1\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu, translations, targets = compute_bleu(val_pred, val_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047242767724880244"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: Même que'il y , , , , de de de de de de , , , , , , , , , , de de de de de de de de la la la la , , , , , , , , de de de de de , de , , , , , , de\n",
      "Target:      S'il existe certainement des personnes qui embrassent l'extrémisme politique pour des raisons politiques , il en existe d'autres qui s'en servent pour cacher leurs agissements criminels - trafic de stupéfiants , trafic de cigarettes , trafic d'êtres humains ils utilisent les idéaux politiques comme un moyen de couvrir leurs activités criminelles . Quoi qu'il en soit , cela est inacceptable .\n",
      "\n",
      "Translation: Nous sommes tous de de de de de de . .\n",
      "Target:      Nous appelons tous de nos vœux une meilleure réaction en cas d'urgence .\n",
      "\n",
      "Translation: Oui , lieu , de de est est , , , , , être être être , , , , et et et\n",
      "Target:      Troisièmement , l'interdiction de la chasse au printemps devrait se baser sur des faits scientifiques et non découler de pressions politiques .\n",
      "\n",
      "Translation: Je ne'ai pas pas de de de de . . .\n",
      "Target:      Je ne dispose pas non plus de la bonne liste des orateurs .\n",
      "\n",
      "Translation: Néanmoins , je pense que les sont de un de , , , , , , de de de de de de de\n",
      "Target:      Néanmoins , je pense que les garanties constituent la bonne approche , si un investisseur privé est prêt à donner une garantie à travers la BEI .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Translation:', translations[i])\n",
    "    print('Target:     ', targets[i])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
