{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path += ['..', '../src']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should initialize our transformer with learnt embeddings, initialize discriminator and add adversarial loss.\n",
    "When we are done with that â€” we are only left with training the thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.vocab import Vocab\n",
    "\n",
    "DATA_PATH = '../data/generated'\n",
    "max_len = 50 # Processing long sentences is slow\n",
    "\n",
    "train_src_path = os.path.join(DATA_PATH, 'train.en.tok.bpe')\n",
    "train_trg_path = os.path.join(DATA_PATH, 'train.de.tok.bpe')\n",
    "val_src_path = os.path.join(DATA_PATH, 'val.en.tok.bpe')\n",
    "val_trg_path = os.path.join(DATA_PATH, 'val.de.tok.bpe')\n",
    "\n",
    "train_src = open(train_src_path, 'r', encoding='utf-8').read().splitlines()\n",
    "train_trg = open(train_trg_path, 'r', encoding='utf-8').read().splitlines()\n",
    "val_src = open(val_src_path, 'r', encoding='utf-8').read().splitlines()\n",
    "val_trg = open(val_trg_path, 'r', encoding='utf-8').read().splitlines()\n",
    "\n",
    "# Simple preprocessing: crop lines and remove empty sentences\n",
    "train_src = [s.split()[:max_len-2] for s in train_src if len(s) != 0]\n",
    "train_trg = [s.split()[:max_len-2] for s in train_trg if len(s) != 0]\n",
    "val_src = [s.split()[:max_len-2] for s in val_src if len(s) != 0]\n",
    "val_trg = [s.split()[:max_len-2] for s in val_trg if len(s) != 0]\n",
    "\n",
    "vocab_src = Vocab.from_file(os.path.join(DATA_PATH, 'vocab.en'))\n",
    "vocab_trg = Vocab.from_file(os.path.join(DATA_PATH, 'vocab.de'))\n",
    "\n",
    "train_src_idx = [[vocab_src.token2id.get(t, vocab_src.unk) for t in s] for s in train_src]\n",
    "train_trg_idx = [[vocab_trg.token2id.get(t, vocab_trg.unk) for t in s] for s in train_trg]\n",
    "val_src_idx = [[vocab_src.token2id.get(t, vocab_src.unk) for t in s] for s in val_src]\n",
    "val_trg_idx = [[vocab_trg.token2id.get(t, vocab_trg.unk) for t in s] for s in val_trg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4462it [00:01, 4082.08it/s]\n",
      "4478it [00:01, 4462.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from src.transformer.models import Transformer\n",
    "from src.utils.data_utils import load_embeddings, init_emb_matrix\n",
    "from src.models import FFN\n",
    "\n",
    "transformer = Transformer(len(vocab_src), len(vocab_trg), max_len)\n",
    "discriminator = FFN(512, 2, 512)\n",
    "\n",
    "# Initializing transformer encoder and decoder with embeddings\n",
    "embeddings_src = load_embeddings('../trained_models/wmt17.en.tok.bpe_cbow.vec')\n",
    "embeddings_trg = load_embeddings('../trained_models/wmt17.de.tok.bpe_cbow.vec')\n",
    "\n",
    "init_emb_matrix(transformer.encoder.src_word_emb.weight.data, embeddings_src, vocab_src.token2id)\n",
    "init_emb_matrix(transformer.decoder.tgt_word_emb.weight.data, embeddings_trg, vocab_trg.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                        \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c6272b8d4897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m                   training_config)\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation_val_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_translate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/neuro_dostoevsky/src/trainer.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(self, training_data, val_data, translation_val_data, plot_every, val_translate_every)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iters_done\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mval_translate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_val_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iters_done\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mplot_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuro_dostoevsky/src/trainer.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mtotal_discriminator_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenvs/zoo/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyvenvs/zoo/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam, RMSprop\n",
    "from tqdm import tqdm\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from src.trainer import Trainer\n",
    "from src.utils.umt_batcher import UMTBatcher\n",
    "from src.utils.data_utils import Batcher\n",
    "import src.transformer.constants as constants\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "def reconstruction_criterion(vocab_size):\n",
    "    ''' With PAD token zero weight '''\n",
    "    weight = torch.ones(vocab_size)\n",
    "    weight[constants.PAD] = 0\n",
    "\n",
    "    return nn.CrossEntropyLoss(weight)\n",
    "\n",
    "reconstruct_src_criterion = reconstruction_criterion(len(vocab_src))\n",
    "reconstruct_trg_criterion = reconstruction_criterion(len(vocab_trg))\n",
    "adv_criterion = nn.BCELoss()\n",
    "\n",
    "transformer_optimizer = Adam([\n",
    "    {'params': transformer.get_trainable_params_without_embs(), 'lr': 1e-4, 'betas': (0.5, 0.999)}, \n",
    "    {'params': transformer.get_embs_parameters(), 'lr': 1e-6, 'betas': (0.9, 0.98)}, \n",
    "])\n",
    "transformer_bt_optimizer = Adam([\n",
    "    {'params': transformer.get_trainable_params_without_embs(), 'lr': 1e-5, 'betas': (0.5, 0.999)}, \n",
    "    {'params': transformer.get_embs_parameters(), 'lr': 5e-7, 'betas': (0.9, 0.98)}, \n",
    "])\n",
    "discriminator_optimizer = Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "training_data = UMTBatcher(train_src_idx, train_trg_idx, vocab_src,\n",
    "                           vocab_trg, batch_size=16, shuffle=False)\n",
    "val_data = UMTBatcher(val_src_idx, val_trg_idx, vocab_src,\n",
    "                      vocab_trg, batch_size=16, shuffle=False)\n",
    "translation_val_data = Batcher(val_src_idx, val_trg_idx, vocab_src.token2id,\n",
    "                               vocab_trg.token2id, batch_size=16, shuffle=False)\n",
    "\n",
    "training_config = {\n",
    "    'max_num_epochs': 5,\n",
    "    'start_bt_from_iter': 2000\n",
    "}\n",
    "\n",
    "trainer = Trainer(transformer, discriminator, vocab_src, vocab_trg,\n",
    "                  transformer_optimizer, transformer_bt_optimizer, discriminator_optimizer,\n",
    "                  reconstruct_src_criterion, reconstruct_trg_criterion, adv_criterion,\n",
    "                  training_config)\n",
    "\n",
    "trainer.run_training(training_data, val_data, translation_val_data, plot_every=50, val_translate_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.bleu import compute_bleu_for_sents\n",
    "from src.utils.data_utils import Batcher\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "val_data = Batcher(val_src_idx, val_trg_idx, vocab_src.token2id,\n",
    "                   vocab_trg.token2id, batch_size=16, shuffle=True)\n",
    "\n",
    "all_translations_src_to_trg = []\n",
    "all_translations_trg_to_src = []\n",
    "all_targets_src_to_trg = []\n",
    "all_targets_trg_to_src = []\n",
    "\n",
    "for test_batch in tqdm(val_data):\n",
    "    translations_src_to_trg = transformer.translate_batch(test_batch[0], max_len=max_len, beam_size=4)\n",
    "    translations_trg_to_src = transformer.translate_batch(test_batch[1], max_len=max_len,\n",
    "                                                    beam_size=6, use_src_embs_in_decoder=True,\n",
    "                                                    use_trg_embs_in_encoder=True)\n",
    "    \n",
    "    translations_src_to_trg = [vocab_trg.remove_bpe(vocab_trg.detokenize(t)) for t in translations_src_to_trg]\n",
    "    translations_trg_to_src = [vocab_src.remove_bpe(vocab_src.detokenize(t)) for t in translations_trg_to_src]\n",
    "\n",
    "    targets_src_to_trg = [vocab_trg.remove_bpe(vocab_trg.detokenize(s)) for s in test_batch[1].data]\n",
    "    targets_trg_to_src = [vocab_src.remove_bpe(vocab_src.detokenize(s)) for s in test_batch[0].data]\n",
    "\n",
    "    translations_src_to_trg = [' '.join(t.split()[:-1]) for t in translations_src_to_trg]\n",
    "    translations_trg_to_src = [' '.join(t.split()[:-1]) for t in translations_trg_to_src]\n",
    "    targets_src_to_trg = [' '.join(t.split()[1:-1]) for t in targets_src_to_trg]\n",
    "    targets_trg_to_src = [' '.join(t.split()[1:-1]) for t in targets_trg_to_src]\n",
    "    \n",
    "    all_translations_src_to_trg += translations_src_to_trg\n",
    "    all_translations_trg_to_src += translations_trg_to_src\n",
    "    all_targets_src_to_trg += targets_src_to_trg\n",
    "    all_targets_trg_to_src += targets_trg_to_src\n",
    "\n",
    "print('BLEU [src->trg]:', compute_bleu_for_sents(all_translations_src_to_trg, all_targets_src_to_trg))\n",
    "print('BLEU [trg->src]:', compute_bleu_for_sents(all_translations_trg_to_src, all_targets_trg_to_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Ein Mann in einem blauen Hemd und blauen Shorts und schwarzen Hosen sitzt auf einem Pferd\n",
      "Target    : Ein brauner Hund rennt mit einem Stock im Maul Ã¼ber den Sand .\n",
      "Prediction: Ein Mann in einem blauen Hemd und blauen Shorts sitzt auf einem Sofa\n",
      "Target    : Ein Fotograf nimmt ein Bild von einem Hinweis auf ein paar TÃ¼ren auf .\n",
      "Prediction: Ein Mann in einem blauen T-Shirt sitzt auf einem Stuhl\n",
      "Target    : Ein Mann in einer grauen Jacke transportiert Laub auf einem Fahrrad .\n",
      "Prediction: Ein Mann fÃ¤hrt auf einem Fahrrad auf\n",
      "Target    : Eine Menschenmasse geht durch den Park .\n",
      "Prediction: Ein Mann in einem blauen T-Shirt und blauen Outfit fÃ¤hrt auf einem\n",
      "Target    : Ein Frau in einer rosafarbenen Bluse zeigt einem Mann in einem gestreiften Pullover , wie eine Handarbeit aus Garn hergestellt wird .\n",
      "Prediction: Ein Mann in einem blauen Hemd und blauen Shorts sitzt auf einer Bank\n",
      "Target    : Eine Frau arbeitet am Wochenende an ihrer Terrasse .\n",
      "Prediction: Ein Mann in einem blauen T-Shirt sitzt auf einem Pferd\n",
      "Target    : Szene eines Mannes beim Schneeschippen , BÃ¼rger , die in einer kalten , winterlichen Umgebung herumlaufen\n",
      "Prediction: Ein Mann in einem schwarzen T-Shirt und blauen Jeans\n",
      "Target    : Reisende beim Wandern an einem sehr kalten Tag .\n",
      "Prediction: Ein Mann in einem blauen Hemd und blauen Hosen\n",
      "Target    : Menschen sitzen zwischen ein paar Pfeilern , wÃ¤hrend eine andere Person vorbeigeht .\n",
      "Prediction: Ein Mann in einem schwarzen Oberteil und mit BaseballmÃ¼tze spielt Gitarre\n",
      "Target    : Drei kleine Hunde schnÃ¼ffeln an etwas .\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Prediction:', all_translations_src_to_trg[i])\n",
    "    print('Target    :', all_targets_src_to_trg[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
