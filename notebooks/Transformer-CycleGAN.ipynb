{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we gonna run experiment with Transformer-CycleGAN. It gonna be cooool!\n",
    "\n",
    "First of all, we should use two transformers: src->trg and trg->src. We gonna sample from them and build cyclic loss:\n",
    "* take two unrelated examples, $x$ from `src` and $y$ from `trg`, translate them: $x \\to \\hat{y}, y \\to \\hat{x}$ and then translate them back. The result should be identical to original values: $x \\to \\hat{y} \\to x$ and $y \\to \\hat{x} \\to y$.\n",
    "\n",
    "We should also try:\n",
    "* using single Transformer for src->trg and trg->src translation (it is capable to do it in supervised regime)\n",
    "* adding noise\n",
    "* adding noise and learning as DAE\n",
    "* using learnt word embeddings\n",
    "* using strong discriminator (Transformer or RNN)\n",
    "* using shared encoder/decoder\n",
    "* using single discriminator\n",
    "* adding normalization between two generators\n",
    "* learning short sentences first and gradually increasing length (cause our time dependencies are way too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path += ['..', '../src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.vocab import Vocab\n",
    "\n",
    "DATA_PATH = '../data/generated'\n",
    "max_len = 50 # Processing long sentences is slow\n",
    "\n",
    "train_src_path = os.path.join(DATA_PATH, 'train.en.tok.bpe')\n",
    "train_trg_path = os.path.join(DATA_PATH, 'train.fr.tok.bpe')\n",
    "val_src_path = os.path.join(DATA_PATH, 'val.en.tok.bpe')\n",
    "val_trg_path = os.path.join(DATA_PATH, 'val.fr.tok.bpe')\n",
    "\n",
    "train_src = open(train_src_path, 'r', encoding='utf-8').read().splitlines()\n",
    "train_trg = open(train_trg_path, 'r', encoding='utf-8').read().splitlines()\n",
    "val_src = open(val_src_path, 'r', encoding='utf-8').read().splitlines()\n",
    "val_trg = open(val_trg_path, 'r', encoding='utf-8').read().splitlines()\n",
    "\n",
    "# Simple preprocessing: crop lines and remove empty sentences\n",
    "train_src = [s.split()[:max_len-2] for s in train_src if len(s) != 0]\n",
    "train_trg = [s.split()[:max_len-2] for s in train_trg if len(s) != 0]\n",
    "val_src = [s.split()[:max_len-2] for s in val_src if len(s) != 0]\n",
    "val_trg = [s.split()[:max_len-2] for s in val_trg if len(s) != 0]\n",
    "\n",
    "vocab_src = Vocab.from_file(os.path.join(DATA_PATH, 'vocab.en'))\n",
    "vocab_trg = Vocab.from_file(os.path.join(DATA_PATH, 'vocab.fr'))\n",
    "\n",
    "train_src_idx = [[vocab_src.token2id.get(t, vocab_src.unk) for t in s] for s in train_src]\n",
    "train_trg_idx = [[vocab_trg.token2id.get(t, vocab_trg.unk) for t in s] for s in train_trg]\n",
    "val_src_idx = [[vocab_src.token2id.get(t, vocab_src.unk) for t in s] for s in val_src]\n",
    "val_trg_idx = [[vocab_trg.token2id.get(t, vocab_trg.unk) for t in s] for s in val_trg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from src.transformer.models import Transformer\n",
    "from src.utils.data_utils import load_embeddings, init_emb_matrix\n",
    "from src.models import TransformerClassifier\n",
    "\n",
    "transformer_kwargs = {\n",
    "    'n_layers': 2,\n",
    "    'n_head': 3,\n",
    "    'd_word_vec': 128,\n",
    "    'd_model': 128,\n",
    "    'd_inner_hid': 256,\n",
    "    'd_k': 32,\n",
    "    'd_v': 32\n",
    "}\n",
    "\n",
    "# transformer_src_to_trg = Transformer(len(vocab_src), len(vocab_trg), max_len)\n",
    "transformer_src_to_trg = Transformer(len(vocab_src), len(vocab_trg), max_len, **transformer_kwargs)\n",
    "discriminator_trg = TransformerClassifier(len(vocab_trg), 2, max_len, **transformer_kwargs)\n",
    "\n",
    "# transformer_trg_to_src = Transformer(len(vocab_trg), len(vocab_src), max_len)\n",
    "transformer_trg_to_src = Transformer(len(vocab_trg), len(vocab_src), max_len, **transformer_kwargs)\n",
    "discriminator_src = TransformerClassifier(len(vocab_src), 2, max_len, **transformer_kwargs)\n",
    "\n",
    "# Initializing transformer encoder and decoder with embeddings\n",
    "# embeddings_src = load_embeddings('../trained_models/europarl.en.tok.bpe_cbow.vec')\n",
    "# embeddings_trg = load_embeddings('../trained_models/europarl.fr.tok.bpe_cbow.vec')\n",
    "\n",
    "# init_emb_matrix(transformer_src_to_trg.encoder.src_word_emb.weight.data, embeddings_src, vocab_src.token2id)\n",
    "# init_emb_matrix(transformer_src_to_trg.decoder.tgt_word_emb.weight.data, embeddings_trg, vocab_trg.token2id)\n",
    "\n",
    "# init_emb_matrix(transformer_trg_to_src.encoder.src_word_emb.weight.data, embeddings_trg, vocab_trg.token2id)\n",
    "# init_emb_matrix(transformer_trg_to_src.decoder.tgt_word_emb.weight.data, embeddings_src, vocab_src.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils.batcher import Batcher\n",
    "\n",
    "# training_data = Batcher(train_src_idx, train_trg_idx, vocab_src.token2id,\n",
    "#                         vocab_trg.token2id, batch_size=2, shuffle=False)\n",
    "\n",
    "# src, trg = next(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10663c470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist([len(s) for s in train_src_idx], bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 48/14500 [03:00<15:04:54,  3.76s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.batcher import Batcher\n",
    "import src.transformer.constants as constants\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "training_data = Batcher(train_src_idx, train_trg_idx, vocab_src.token2id,\n",
    "                        vocab_trg.token2id, batch_size=2, shuffle=False)\n",
    "\n",
    "\n",
    "def reconstruction_criterion(vocab_size):\n",
    "    ''' With PAD token zero weight '''\n",
    "    weight = torch.ones(vocab_size)\n",
    "    weight[constants.PAD] = 0\n",
    "\n",
    "    return nn.CrossEntropyLoss(weight)\n",
    "\n",
    "\n",
    "adv_criterion = nn.BCEWithLogitsLoss()\n",
    "reconstruct_src_criterion = reconstruction_criterion(len(vocab_src))\n",
    "reconstruct_trg_criterion = reconstruction_criterion(len(vocab_trg))\n",
    "\n",
    "transformer_src_to_trg_optimizer = Adam(transformer_src_to_trg.get_trainable_parameters(), lr=1e-4)\n",
    "transformer_trg_to_src_optimizer = Adam(transformer_trg_to_src.get_trainable_parameters(), lr=1e-4)\n",
    "discriminator_src_optimizer = Adam(discriminator_src.get_trainable_parameters(), lr=1e-4)\n",
    "discriminator_trg_optimizer = Adam(discriminator_trg.get_trainable_parameters(), lr=1e-4)\n",
    "\n",
    "for src, trg in tqdm(training_data):\n",
    "    # Normal forward pass\n",
    "    preds_src_to_trg = transformer_src_to_trg.differentiable_translate(src, vocab_trg)\n",
    "    preds_trg_to_src = transformer_trg_to_src.differentiable_translate(trg, vocab_src)\n",
    "    \n",
    "    # Running our discriminators to predict domains\n",
    "    # Target discriminator\n",
    "    true_domains_preds_trg = discriminator_trg(trg)\n",
    "    fake_domains_preds_trg = discriminator_trg(preds_src_to_trg, one_hot_input=True)\n",
    "    true_domains_preds_src = discriminator_src(src)\n",
    "    fake_domains_preds_src = discriminator_src(preds_trg_to_src, one_hot_input=True)\n",
    "    \n",
    "    true_domains_y_trg = Variable(torch.zeros(len(true_domains_preds_trg)))\n",
    "    fake_domains_y_trg = Variable(torch.ones(len(fake_domains_preds_trg)))\n",
    "    true_domains_y_src = Variable(torch.zeros(len(true_domains_preds_src)))\n",
    "    fake_domains_y_src = Variable(torch.ones(len(fake_domains_preds_src)))\n",
    "    \n",
    "    # Revert classes for generator\n",
    "    fake_domains_y_trg_for_gen = Variable(torch.zeros(len(fake_domains_preds_trg)))\n",
    "    fake_domains_y_src_for_gen = Variable(torch.zeros(len(fake_domains_preds_src)))\n",
    "    \n",
    "    if use_cuda:\n",
    "        true_domains_y_trg.cuda()\n",
    "        fake_domains_y_trg.cuda()\n",
    "        true_domains_y_src.cuda()\n",
    "        fake_domains_y_src.cuda()\n",
    "        fake_domains_y_trg_for_gen.cuda()\n",
    "        fake_domains_y_src_for_gen.cuda()\n",
    "    \n",
    "    discr_src_loss_on_true = adv_criterion(true_domains_preds_trg, true_domains_y_trg)\n",
    "    discr_src_loss_on_fake = adv_criterion(fake_domains_preds_trg, fake_domains_y_trg)\n",
    "    discr_trg_loss_on_true = adv_criterion(true_domains_preds_trg, true_domains_y_trg)\n",
    "    discr_trg_loss_on_fake = adv_criterion(fake_domains_preds_trg, fake_domains_y_trg)\n",
    "    discr_src_loss = discr_src_loss_on_true + discr_src_loss_on_fake\n",
    "    discr_trg_loss = discr_trg_loss_on_true + discr_trg_loss_on_fake\n",
    "    \n",
    "    # Uff, ok. Let's compute losses for our generators\n",
    "    gen_src_to_trg_loss = adv_criterion(fake_domains_preds_trg, fake_domains_y_trg_for_gen)\n",
    "    gen_trg_to_src_loss = adv_criterion(fake_domains_preds_src, fake_domains_y_src_for_gen)\n",
    "    \n",
    "    # \"Back-translation\" passes\n",
    "    preds_src_to_trg_to_src = transformer_trg_to_src(preds_src_to_trg, src, one_hot_src=True)\n",
    "    preds_trg_to_src_to_trg = transformer_src_to_trg(preds_trg_to_src, trg, one_hot_src=True)\n",
    "    \n",
    "    # Trying to reconstruct what we have just back-translated\n",
    "    src_reconstruction_loss = reconstruct_src_criterion(preds_src_to_trg_to_src, src[:, 1:].contiguous().view(-1))\n",
    "    trg_reconstruction_loss = reconstruct_trg_criterion(preds_trg_to_src_to_trg, trg[:, 1:].contiguous().view(-1))\n",
    "    \n",
    "    ### Update weights ###\n",
    "    # Let's update discriminators first and forget about them instantly\n",
    "    discriminator_src_optimizer.zero_grad()\n",
    "    discriminator_trg_optimizer.zero_grad()\n",
    "    discr_src_loss.backward(retain_graph=True)\n",
    "    discr_trg_loss.backward(retain_graph=True)\n",
    "    discriminator_src_optimizer.step()\n",
    "    discriminator_trg_optimizer.step()\n",
    "    \n",
    "    # Now let's optimize reconstruction and generator losses\n",
    "    transformer_src_to_trg_optimizer.zero_grad()\n",
    "    transformer_trg_to_src_optimizer.zero_grad()\n",
    "\n",
    "    src_reconstruction_loss.backward(retain_graph=True)\n",
    "    trg_reconstruction_loss.backward(retain_graph=True)\n",
    "    gen_src_to_trg_loss.backward(retain_graph=True)\n",
    "    gen_trg_to_src_loss.backward(retain_graph=True)\n",
    "    \n",
    "    transformer_src_to_trg_optimizer.step()\n",
    "    transformer_trg_to_src_optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
