title: "AutoEncoder with Transformer Embedder"
trainer: "TransformerEmbedderTrainer"
# data: "data/multi30k/train.en"
data: "data/yelp/yelp-positive-short.en.tok.bpe"
max_num_epochs: 30
val_freq_iters: 1000
val_set_size: 1000
random_seed: 42
modules:
  models: ["encoder", "embedder", "decoder"]
  optims: ["optim"]
hp:
  lr: 0.001
  batch_size: 128
  min_len: 10
  max_len: 50
  transformer:
    n_vecs: 2
    d_model: 512
    dropout: 0.1
    n_steps: 4
    pe_max_len: 100
    n_heads: 4
    d_ff: 1024
